# app.py - ì•…ë³´ ì¸ì‹ ì„œë²„
from flask import Flask, request, jsonify
import cv2
import numpy as np
import base64
from PIL import Image, ImageDraw, ImageFont
import io
import json

app = Flask(__name__)

# ê¸°ë³¸ í•¨ìˆ˜ë“¤ (ì•ì„œ ì œê³µí•´ì£¼ì‹  ì½”ë“œ ê¸°ë°˜)
def threshold(image):
    """ì´ë¯¸ì§€ ì´ì§„í™”"""
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)
    return image

def weighted(value, standard=10):
    """ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    return int(value * (standard / 10))

def closing(image, standard=10):
    """ë‹«í˜ ì—°ì‚°"""
    kernel = np.ones((weighted(5, standard), weighted(5, standard)), np.uint8)
    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
    return image

def get_center(y, h):
    """ê°ì²´ ì¤‘ì‹¬ì  ê³„ì‚°"""
    return (y + y + h) / 2

def remove_noise(image):
    """ë³´í‘œ ì˜ì—­ë§Œ ì¶”ì¶œ"""
    image = threshold(image)
    mask = np.zeros(image.shape, np.uint8)
    cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(image)
    
    for i in range(1, cnt):
        x, y, w, h, area = stats[i]
        if w > image.shape[1] * 0.5:  # ì´ë¯¸ì§€ ë„“ì´ì˜ 50% ì´ìƒ
            cv2.rectangle(mask, (x, y, w, h), (255, 0, 0), -1)
    
    masked_image = cv2.bitwise_and(image, mask)
    return masked_image

def remove_staves(image):
    """ì˜¤ì„  ì œê±°"""
    height, width = image.shape
    staves = []
    
    # ì˜¤ì„  ê²€ì¶œ
    for row in range(height):
        pixels = 0
        for col in range(width):
            pixels += (image[row][col] == 255)
        
        if pixels >= width * 0.5:
            if len(staves) == 0 or abs(staves[-1][0] + staves[-1][1] - row) > 1:
                staves.append([row, 1])
            else:
                staves[-1][1] += 1
    
    # ì˜¤ì„  ì œê±°
    for staff in range(len(staves)):
        top_pixel = staves[staff][0]
        bot_pixel = staves[staff][0] + staves[staff][1]
        
        for col in range(width):
            if (top_pixel > 0 and bot_pixel < height-1 and 
                image[top_pixel - 1][col] == 0 and 
                image[bot_pixel + 1][col] == 0):
                for row in range(top_pixel, bot_pixel + 1):
                    image[row][col] = 0
    
    return image, [x[0] for x in staves]

def normalization(image, staves, standard=10):
    """ì´ë¯¸ì§€ ì •ê·œí™”"""
    if len(staves) < 5:
        return image, staves
    
    avg_distance = 0
    lines = int(len(staves) / 5)
    
    for line in range(lines):
        for staff in range(4):
            if line * 5 + staff + 1 < len(staves):
                staff_above = staves[line * 5 + staff]
                staff_below = staves[line * 5 + staff + 1]
                avg_distance += abs(staff_above - staff_below)
    
    if avg_distance == 0:
        return image, staves
    
    avg_distance /= len(staves) - lines
    height, width = image.shape
    weight = standard / avg_distance
    
    new_width = int(width * weight)
    new_height = int(height * weight)
    
    image = cv2.resize(image, (new_width, new_height))
    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    staves = [x * weight for x in staves]
    
    return image, staves

def object_detection(image, staves, standard=10):
    """ê°ì²´ ê²€ì¶œ"""
    if len(staves) < 5:
        return image, []
    
    lines = int(len(staves) / 5)
    objects = []
    closing_image = closing(image, standard)
    cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(closing_image)
    
    for i in range(1, cnt):
        (x, y, w, h, area) = stats[i]
        if w >= weighted(5, standard) and h >= weighted(5, standard):
            center = get_center(y, h)
            for line in range(lines):
                area_top = staves[line * 5] - weighted(20, standard)
                area_bot = staves[(line + 1) * 5 - 1] + weighted(20, standard)
                if area_top <= center <= area_bot:
                    objects.append([line, (x, y, w, h, area)])
    
    objects.sort()
    return image, objects

def analyze_note_positions(objects, staves, standard=10):
    """ìŒí‘œ ìœ„ì¹˜ ë¶„ì„í•˜ì—¬ ê³„ì´ë¦„ ê²°ì •"""
    notes = []
    
    if len(staves) < 5:
        return notes
    
    # ê¸°ë³¸ì ì¸ ê³„ì´ë¦„ ë§¤í•‘ (íŠ¸ë ˆë¸” í´ë ˆí”„ ê¸°ì¤€)
    # ì˜¤ì„  ê°„ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ìŒë†’ì´ ê³„ì‚°
    for obj in objects:
        line_num, (x, y, w, h, area) = obj
        
        if line_num * 5 + 4 >= len(staves):
            continue
            
        # í•´ë‹¹ ë³´í‘œì˜ ì˜¤ì„ ë“¤
        staff_lines = staves[line_num * 5:line_num * 5 + 5]
        center_y = y + h // 2
        
        # ì˜¤ì„  ê°„ê²© ê³„ì‚°
        if len(staff_lines) >= 2:
            line_spacing = (staff_lines[-1] - staff_lines[0]) / 4
            
            # ê¸°ì¤€ì„ (ë‘ ë²ˆì§¸ ì˜¤ì„ , íŠ¸ë ˆë¸” í´ë ˆí”„ì˜ ì†”)ì—ì„œì˜ ê±°ë¦¬
            reference_line = staff_lines[1]  # ë‘ ë²ˆì§¸ ì˜¤ì„  (ì†”)
            distance_from_sol = (reference_line - center_y) / line_spacing
            
            # ê±°ë¦¬ì— ë”°ë¥¸ ê³„ì´ë¦„ ê²°ì •
            note_names = ['ë„', 'ë ˆ', 'ë¯¸', 'íŒŒ', 'ì†”', 'ë¼', 'ì‹œ']
            
            # ì†”(ë‘ ë²ˆì§¸ ì˜¤ì„ )ì„ ê¸°ì¤€(ì¸ë±ìŠ¤ 4)ìœ¼ë¡œ ê³„ì‚°
            note_index = int(round(distance_from_sol)) + 4
            
            # ë²”ìœ„ ë‚´ì—ì„œ ê³„ì´ë¦„ ê²°ì •
            if 0 <= note_index < len(note_names):
                note_name = note_names[note_index]
            else:
                # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì˜¥íƒ€ë¸Œ ê³„ì‚°
                octave_offset = note_index // len(note_names)
                adjusted_index = note_index % len(note_names)
                note_name = note_names[adjusted_index]
                if octave_offset > 0:
                    note_name += f"(+{octave_offset})"
                elif octave_offset < 0:
                    note_name += f"({octave_offset})"
            
            notes.append({
                'x': x,
                'y': y,
                'width': w,
                'height': h,
                'note_name': note_name,
                'center_x': x + w // 2,
                'center_y': center_y
            })
    
    return notes

def overlay_note_names(original_image, notes, settings):
    """ê³„ì´ë¦„ì„ ì´ë¯¸ì§€ì— ì˜¤ë²„ë ˆì´"""
    # OpenCV ì´ë¯¸ì§€ë¥¼ PILë¡œ ë³€í™˜
    pil_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_image)
    
    # í°íŠ¸ ì„¤ì •
    font_size = settings.get('fontSize', 24)
    font_color = settings.get('fontColor', '#000000')
    
    try:
        # ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", font_size)
    except:
        font = ImageFont.load_default()
    
    # ê° ìŒí‘œ ì•„ë˜ì— ê³„ì´ë¦„ í‘œì‹œ
    for note in notes:
        text = note['note_name']
        x = note['center_x']
        y = note['y'] + note['height'] + 5  # ìŒí‘œ ì•„ë˜ìª½ì— í‘œì‹œ
        
        # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_x = x - text_width // 2  # ì¤‘ì•™ ì •ë ¬
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw.text((text_x, y), text, fill=font_color, font=font)
    
    # PILì„ ë‹¤ì‹œ OpenCVë¡œ ë³€í™˜
    result_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    return result_image

@app.route('/analyze-sheet-music', methods=['POST'])
def analyze_sheet_music():
    """ì•…ë³´ ë¶„ì„ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        data = request.json
        image_base64 = data['image']
        note_settings = data.get('settings', {})
        
        print("ì•…ë³´ ë¶„ì„ ì‹œì‘...")
        
        # Base64 ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        image_data = base64.b64decode(image_base64)
        nparr = np.frombuffer(image_data, np.uint8)
        original_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if original_image is None:
            return jsonify({'success': False, 'error': 'ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
        
        print("ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ")
        
        # ì•…ë³´ ì¸ì‹ ì²˜ë¦¬ ê³¼ì •
        # 1. ì „ì²˜ë¦¬
        processed_image = remove_noise(original_image.copy())
        print("ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ")
        
        # 2. ì˜¤ì„  ì œê±°
        no_staves_image, staves = remove_staves(processed_image.copy())
        print(f"ì˜¤ì„  ì œê±° ì™„ë£Œ, ê²€ì¶œëœ ì˜¤ì„ : {len(staves)}ê°œ")
        
        # 3. ì •ê·œí™”
        normalized_image, normalized_staves = normalization(no_staves_image.copy(), staves.copy())
        print("ì •ê·œí™” ì™„ë£Œ")
        
        # 4. ê°ì²´ ê²€ì¶œ
        final_image, objects = object_detection(normalized_image.copy(), normalized_staves.copy())
        print(f"ê°ì²´ ê²€ì¶œ ì™„ë£Œ, ê²€ì¶œëœ ê°ì²´: {len(objects)}ê°œ")
        
        # 5. ìŒí‘œ ìœ„ì¹˜ ë¶„ì„
        notes = analyze_note_positions(objects, normalized_staves)
        print(f"ìŒí‘œ ë¶„ì„ ì™„ë£Œ, ë¶„ì„ëœ ìŒí‘œ: {len(notes)}ê°œ")
        
        # 6. ê³„ì´ë¦„ ì˜¤ë²„ë ˆì´
        result_image = overlay_note_names(original_image, notes, note_settings)
        print("ê³„ì´ë¦„ ì˜¤ë²„ë ˆì´ ì™„ë£Œ")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜
        _, buffer = cv2.imencode('.png', result_image)
        result_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return jsonify({
            'success': True,
            'result_image': result_base64,
            'notes_detected': len(notes),
            'notes': notes,
            'staves_detected': len(staves),
            'objects_detected': len(objects)
        })
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({'status': 'healthy', 'message': 'ì•…ë³´ ì¸ì‹ ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.'})

if __name__ == '__main__':
    print("ğŸµ ì•…ë³´ ì¸ì‹ ì„œë²„ ì‹œì‘...")
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:5000")
    print("ğŸ” ìƒíƒœ í™•ì¸: http://localhost:5000/health")
    print("ğŸ“ API ì—”ë“œí¬ì¸íŠ¸: POST /analyze-sheet-music")
    app.run(host='0.0.0.0', port=5001, debug=True)